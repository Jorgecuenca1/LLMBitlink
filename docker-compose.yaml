version: '3.8'

x-defaults: &default-env
  restart: always
  networks:
    - backend

x-airflow-common: &airflow-common
  build: './airflow'
  image: ${AIRFLOW_IMAGE_NAME:-extending_airflow:latest}
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${PG_USER:-airflow}:${PG_PASSWORD:-airflow}@postgres:5432/airflow
    AIRFLOW__WEBSERVER__SECRET_KEY: base64encodedFernetKeyHere
    AIRFLOW__WEBSERVER__PORT: 8081
    AIRFLOW__CORE__DAG_CONCURRENCY: 16
    AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 16
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.session'
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'True'
    AIRFLOW__SECRETS__BACKEND: 'airflow.secrets.local_filesystem.LocalFilesystemBackend'
    AIRFLOW__SECRETS__BACKEND_KWARGS: '{"variables_file_path": "/opt/secrets/variables.json"}'
    AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY:-minio}
    AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_ACCESS_KEY:-minio123}
    AWS_ENDPOINT_URL_S3: http://s3:9000
    MLFLOW_S3_ENDPOINT_URL: http://s3:9000
  volumes:
    - ${AIRFLOW_PROJ_DIR:-./airflow}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-./airflow}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-./airflow}/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-./airflow}/plugins:/opt/airflow/plugins
    - ${AIRFLOW_PROJ_DIR:-./airflow}/secrets:/opt/secrets
    - ${AIRFLOW_PROJ_DIR:-./config}/airflow.cfg:/opt/airflow/airflow.cfg  # Mount the config file
  networks:
    - backend
  depends_on:
    - postgres

services:
  postgres:
    image: postgres:13
    container_name: postgres_airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      POSTGRES_MULTIPLE_DATABASES: 'airflow_db,mlflow_db'
    volumes:
      - ./create-multiple-postgresql-databases.sh:/docker-entrypoint-initdb.d/create-multiple-postgresql-databases.sh
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 5

  minio:
    image: minio/minio
    container_name: minio_storage
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  mlflow:
    build: ./mlflow
    env_file:
      - .env
    container_name: mlflow_tracking
    depends_on:
      - postgres
      - minio
    ports:
      - "5000:5000"
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio123
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 20s
      retries: 3

  fastapi:
    build: ./app
    env_file:
      - .env
    volumes:
      - ./data:/data
    container_name: fastapi_server
    depends_on:
      - mlflow
    ports:
      - "8800:8000"
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      HUGGINGFACE_TOKEN: "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"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_web_server
    depends_on:
      postgres:
        condition: service_healthy
    command: ["sh", "-c", "/wait-for-it.sh postgres:5432 -- airflow webserver"]
    ports:
      - "8081:8081"
    user: "50000:0"

networks:
  backend:
    driver: bridge

volumes:
  postgres_data:
  minio_data:
